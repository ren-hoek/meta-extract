{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "657faca0-c88f-4138-8c62-cf9974e0c894",
    "_uuid": "b30a120404b8e104774a292b45f0902e89acef68"
   },
   "source": [
    "# Bottleneck features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: \n",
    "\n",
    "- If working in offline environment then need to save models in ~/.keras/models or it will automatically attempt to download\n",
    "- I moved a few .jpeg images into a local folder for testing the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "d4c4a3a8-93af-4cd2-a95b-32a2526ac3a2",
    "_uuid": "151b0f031d10c081017bee0831d1e276148b413b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import listdir\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import inception_v3, xception, vgg16, resnet50\n",
    "import h5py as h5py\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "8bcb2bda-88dc-4ad8-9177-0c126401c3e1",
    "_uuid": "3f62e82d998e8b2ba3999542492e632c5083a901"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images: 5\n"
     ]
    }
   ],
   "source": [
    "INPUT_SIZE = 299\n",
    "data_dir = '/notebooks/data_test/' #<-----Local foloder on my machine with a few jpgs in it.\n",
    "num_records=len(listdir((data_dir)))\n",
    "print(\"number of images: \" + str(len(listdir((data_dir)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creat list of image filepaths\n",
    "image_path_list=[]\n",
    "for path, subdirs, files in os.walk(data_dir):\n",
    "    for name in files:\n",
    "        image_path_list.append((os.path.join(path, name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "c48fc864-d70f-4045-96eb-12de12c0ad41",
    "_uuid": "7d26cc67909b5bd70173b5f2ed8352b210e06fb3"
   },
   "outputs": [],
   "source": [
    "def read_img(img_id, size):\n",
    "    \"\"\"Read and resize image.\n",
    "    # Arguments\n",
    "        img_id: string\n",
    "        size: resize the original image.\n",
    "    # Returns\n",
    "        Image as numpy array.\n",
    "    \"\"\"\n",
    "    img = image.load_img(img_id,target_size=size)\n",
    "    img = image.img_to_array(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that different models required different input sizes\n",
    "- Xception (299x299)\n",
    "- Inception (299x299)\n",
    "- VGG (244x244)\n",
    "- Res50 (244x244)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "c9e29a84-5cad-49d7-9290-5f7755cb1d43",
    "_uuid": "e8f19dc62979a04aaa396f9cd9b990751d372286"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 87.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images shape: (5, 299, 299, 3) size: 1,341,015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Read images to array\n",
    "POOLING = 'avg'\n",
    "x_train = np.zeros((num_records, INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\n",
    "for i, img_id in enumerate(tqdm(image_path_list)):\n",
    "    img = read_img(img_id, (INPUT_SIZE, INPUT_SIZE))\n",
    "    x = xception.preprocess_input(np.expand_dims(img.copy(), axis=0))\n",
    "    x_train[i] = x\n",
    "print('Train Images shape: {} size: {:,}'.format(x_train.shape, x_train.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "37a9f47a-9a17-43cd-99b3-7f89192ccf34",
    "_uuid": "1508b3285ea437bf24aa765c76ea56042d406034"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 240ms/step\n",
      "Xception train bottleneck features shape: (5, 2048) size: 10,240\n"
     ]
    }
   ],
   "source": [
    "# Extract bottleneck features\n",
    "\n",
    "xception_bottleneck = xception.Xception(weights='imagenet', include_top=False, pooling=POOLING)\n",
    "train_x_bf = xception_bottleneck.predict(x_train, batch_size=32, verbose=1)\n",
    "print('Xception train bottleneck features shape: {} size: {:,}'.format(train_x_bf.shape, train_x_bf.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 181.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images shape: (5, 299, 299, 3) size: 1,341,015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "POOLING = 'avg'\n",
    "x_train = np.zeros((num_records, INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\n",
    "for i, img_id in enumerate(tqdm(image_path_list)):\n",
    "    img = read_img(img_id, (INPUT_SIZE, INPUT_SIZE))\n",
    "    x = inception_v3.preprocess_input(np.expand_dims(img.copy(), axis=0))\n",
    "    x_train[i] = x\n",
    "print('Train Images shape: {} size: {:,}'.format(x_train.shape, x_train.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 342ms/step\n",
      "InceptionV3 train bottleneck features shape: (5, 2048) size: 10,240\n"
     ]
    }
   ],
   "source": [
    "inception_bottleneck = inception_v3.InceptionV3(weights='imagenet', include_top=False, pooling=POOLING)\n",
    "train_i_bf = inception_bottleneck.predict(x_train, batch_size=32, verbose=1)\n",
    "print('InceptionV3 train bottleneck features shape: {} size: {:,}'.format(train_i_bf.shape, train_i_bf.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 170.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images shape: (5, 224, 224, 3) size: 752,640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "POOLING = 'avg'\n",
    "x_train = np.zeros((num_records, INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\n",
    "for i, img_id in enumerate(tqdm(image_path_list)):\n",
    "    img = read_img(img_id, (INPUT_SIZE, INPUT_SIZE))\n",
    "    x = vgg16.preprocess_input(np.expand_dims(img.copy(), axis=0))\n",
    "    x_train[i] = x\n",
    "print('Train Images shape: {} size: {:,}'.format(x_train.shape, x_train.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 247ms/step\n",
      "VGG train bottleneck features shape: (5, 512) size: 2,560\n"
     ]
    }
   ],
   "source": [
    "vgg_bottleneck = vgg16.vgg16.VGG16(weights='imagenet', include_top=False, pooling=POOLING)\n",
    "train_vgg_bf = vgg_bottleneck.predict(x_train, batch_size=32, verbose=1)\n",
    "print('VGG train bottleneck features shape: {} size: {:,}'.format(train_vgg_bf.shape, train_vgg_bf.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Res50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 181.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images shape: (5, 224, 224, 3) size: 752,640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_train = np.zeros((num_records, INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\n",
    "for i, img_id in enumerate(tqdm(image_path_list)):\n",
    "    img = read_img(img_id, (INPUT_SIZE, INPUT_SIZE))\n",
    "    x = resnet50.preprocess_input(np.expand_dims(img.copy(), axis=0))\n",
    "    x_train[i] = x\n",
    "print('Train Images shape: {} size: {:,}'.format(x_train.shape, x_train.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 233ms/step\n",
      "Res50 train bottleneck features shape: (5, 2048) size: 10,240\n"
     ]
    }
   ],
   "source": [
    "res50_bottleneck = resnet50.resnet50.ResNet50(weights='imagenet', include_top=False, pooling=POOLING)\n",
    "train_res50_bf = res50_bottleneck.predict(x_train, batch_size=32, verbose=1)\n",
    "print('Res50 train bottleneck features shape: {} size: {:,}'.format(train_res50_bf.shape, train_res50_bf.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is probably inefficient to read the images into separate arrays four times.\n",
    "- I'm not sure it matters too much where preprocess_input is run from (i.e. VGG, Imagenet etc.)\n",
    "- It may be possible to read the images into a 299 array and then simply resize down to 224 for the models that require  that size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
